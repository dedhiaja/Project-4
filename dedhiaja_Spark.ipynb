{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a98dafe-8553-4c69-954d-34e003fa626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Jash Dedhia\n",
    "# Date: 2nd Nov, 2024\n",
    "# Project 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae0d1f9-89d5-42e1-801f-ff9d0f14a7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdbe97a-4272-42d9-9bbf-53750b73b084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dedhi\\anaconda3\\envs\\pyspark_env\\lib\\site-packages (from beautifulsoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cd8e5-e21c-4e16-8d6d-8a9745467a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 2:\n",
      "Downloaded: ./weather_data\\2015_72429793812.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"\\nAnswer to Question 2:\")\n",
    "\n",
    "# Base URL for NCEI Bulk Data Download\n",
    "base_url = \"https://www.ncei.noaa.gov/data/global-summary-of-the-day/access\"\n",
    "data_directory = \"./weather_data\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "# Download weather data for Cincinnati and Florida for years 2015 to 2024\n",
    "years = range(2015, 2025)\n",
    "stations = [\"72429793812\", \"99495199999\"]\n",
    "\n",
    "def download_file(url, local_filename):\n",
    "    \"\"\"Download file from a URL and save it locally.\"\"\"\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        if r.status_code == 200:\n",
    "            with open(local_filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Downloaded: {local_filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {url}\")\n",
    "\n",
    "for year in years:\n",
    "    year_url = f\"{base_url}/{year}/\"\n",
    "    response = requests.get(year_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error accessing: {year_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parse HTML to find all file links\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    # Download data for each station and year\n",
    "    for station in stations:\n",
    "        filename = f\"{station}.csv\"\n",
    "        for link in links:\n",
    "            if link.get('href') == filename:\n",
    "                file_url = f\"{year_url}{filename}\"\n",
    "                local_path = os.path.join(data_directory, f\"{year}_{filename}\")\n",
    "                download_file(file_url, local_path)\n",
    "                break\n",
    "\n",
    "# List to store the counts of the datasets\n",
    "dataset_counts = []\n",
    "\n",
    "for year in years:\n",
    "    for station in stations:\n",
    "        # Skip 2016 for Florida as data is not available\n",
    "        if year == 2016 and station == \"99495199999\":\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(data_directory, f\"{year}_{station}.csv\")\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Read the CSV file using Pandas\n",
    "            df = pd.read_csv(file_path)\n",
    "            row_count = len(df)\n",
    "            dataset_counts.append((year, station, row_count))\n",
    "            location = \"Cincinnati\" if station == \"72429793812\" else \"Florida\"\n",
    "            print(f\"{location} --> Year: {year}, Station: {station}, Count: {row_count}\")\n",
    "        else:\n",
    "            print(f\"File not found for Year: {year}, Station: {station}\")\n",
    "\n",
    "# Display total results\n",
    "if len(dataset_counts) == 19:\n",
    "    print(\"\\nTotal Results: 19 (as expected)\")\n",
    "else:\n",
    "    print(f\"\\nTotal Results: {len(dataset_counts)} (unexpected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "737726e6-8b80-45ec-bdfd-62a3f1c034d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cincinnati Data Count (Total Number of Rows): 3588\n",
      "Florida Data Count (Total Number of Rows)   : 2483\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "data_directory = \"./weather_data\"\n",
    "\n",
    "# Years for which data is available\n",
    "years = range(2015, 2025)\n",
    "\n",
    "# List CSV files for Cincinnati and Florida\n",
    "cincinnati_files = [f\"{data_directory}/{year}_72429793812.csv\" for year in years]\n",
    "florida_files = [f\"{data_directory}/{year}_99495199999.csv\" for year in years if year != 2016]  # Exclude 2016 for Florida\n",
    "\n",
    "# Load data from CSV files into Pandas DataFrames\n",
    "cincinnati_dfs = [pd.read_csv(file) for file in cincinnati_files if os.path.exists(file)]\n",
    "florida_dfs = [pd.read_csv(file) for file in florida_files if os.path.exists(file)]\n",
    "\n",
    "# Concatenate all DataFrames for Cincinnati and Florida\n",
    "cincinnati_df = pd.concat(cincinnati_dfs, ignore_index=True)\n",
    "florida_df = pd.concat(florida_dfs, ignore_index=True)\n",
    "\n",
    "# Display total row counts\n",
    "print(f\"Cincinnati Data Count (Total Number of Rows): {len(cincinnati_df)}\")\n",
    "print(f\"Florida Data Count (Total Number of Rows)   : {len(florida_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a483ec19-65ba-4e07-b1f4-188c4421db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 3\n",
      "\n",
      "Hottest Days by Year (Cincinnati):\n",
      "\n",
      "╒════════╤═════════════╤══════════════════════════════════════════════════╤════════════╤═══════╕\n",
      "│   YEAR │     STATION │ NAME                                             │ DATE       │   MAX │\n",
      "╞════════╪═════════════╪══════════════════════════════════════════════════╪════════════╪═══════╡\n",
      "│   2015 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2015-06-12 │  91.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2016 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2016-07-24 │  93.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2017 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-07-22 │  91.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2018 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2018-07-04 │  96.1 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2019 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2019-09-30 │  95.0 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2020 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2020-07-05 │  93.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2021 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2021-08-12 │  95.0 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2022 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2022-06-14 │  96.1 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2023 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2023-08-23 │  96.1 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2024 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2024-08-30 │ 100.9 │\n",
      "╘════════╧═════════════╧══════════════════════════════════════════════════╧════════════╧═══════╛\n",
      "\n",
      "Hottest Days by Year (Florida):\n",
      "\n",
      "╒════════╤═════════════╤═══════════════════════════════════╤════════════╤═══════╕\n",
      "│   YEAR │     STATION │ NAME                              │ DATE       │   MAX │\n",
      "╞════════╪═════════════╪═══════════════════════════════════╪════════════╪═══════╡\n",
      "│   2015 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2015-07-28 │  90.0 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2017 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2017-05-13 │  88.3 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2018 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2018-09-15 │  90.1 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2019 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2019-09-06 │  91.6 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2020 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2020-04-13 │  91.8 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2021 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2021-04-18 │  86.2 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2022 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2022-05-06 │  89.6 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2023 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2023-07-09 │  90.9 │\n",
      "├────────┼─────────────┼───────────────────────────────────┼────────────┼───────┤\n",
      "│   2024 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US │ 2024-05-14 │  86.7 │\n",
      "╘════════╧═════════════╧═══════════════════════════════════╧════════════╧═══════╛\n",
      "\n",
      "Overall Hottest Day by Year (Cincinnati and Florida):\n",
      "\n",
      "╒════════╤═════════════╤══════════════════════════════════════════════════╤════════════╤═══════╕\n",
      "│   YEAR │     STATION │ NAME                                             │ DATE       │   MAX │\n",
      "╞════════╪═════════════╪══════════════════════════════════════════════════╪════════════╪═══════╡\n",
      "│   2015 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2015-06-12 │  91.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2016 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2016-07-24 │  93.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2017 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-07-22 │  91.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2018 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2018-07-04 │  96.1 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2019 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2019-09-30 │  95.0 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2020 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2020-07-05 │  93.9 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2021 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2021-08-12 │  95.0 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2022 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2022-06-14 │  96.1 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2023 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2023-08-23 │  96.1 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼────────────┼───────┤\n",
      "│   2024 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2024-08-30 │ 100.9 │\n",
      "╘════════╧═════════════╧══════════════════════════════════════════════════╧════════════╧═══════╛\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"\\nAnswer to Question 3:\")\n",
    "\n",
    "# Directory and years range\n",
    "data_directory = \"./weather_data\"\n",
    "years = range(2015, 2025)\n",
    "stations = [\"72429793812\", \"99495199999\"]\n",
    "\n",
    "# Store hottest days data for Cincinnati, Florida, and overall hottest day per year\n",
    "hottest_days_cincinnati = []\n",
    "hottest_days_florida = []\n",
    "hottest_days_overall = []\n",
    "\n",
    "# Find hottest day for each year in Cincinnati and Florida, and then compare\n",
    "for year in years:\n",
    "    year_data = []\n",
    "    for station in stations:\n",
    "        # Skip 2016 for Florida as data may not be available\n",
    "        if year == 2016 and station == \"99495199999\":\n",
    "            continue\n",
    "\n",
    "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            # Load data and filter out invalid temperature values\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df[df[\"MAX\"] != 9999.9]\n",
    "\n",
    "            # Find the hottest day for this station if data is available\n",
    "            if not df.empty:\n",
    "                hottest_day = df.loc[df[\"MAX\"].idxmax()]\n",
    "                hottest_day_data = {\n",
    "                    \"YEAR\": year,\n",
    "                    \"STATION\": hottest_day[\"STATION\"],\n",
    "                    \"NAME\": hottest_day[\"NAME\"],\n",
    "                    \"DATE\": hottest_day[\"DATE\"],\n",
    "                    \"MAX\": hottest_day[\"MAX\"]\n",
    "                }\n",
    "                year_data.append(hottest_day_data)\n",
    "\n",
    "                # Separate lists for Cincinnati and Florida\n",
    "                if station == \"72429793812\":\n",
    "                    hottest_days_cincinnati.append(hottest_day_data)\n",
    "                elif station == \"99495199999\":\n",
    "                    hottest_days_florida.append(hottest_day_data)\n",
    "\n",
    "    # Determine the hottest day overall for the year by comparing both stations\n",
    "    if year_data:\n",
    "        hottest_day_year = max(year_data, key=lambda x: x[\"MAX\"])\n",
    "        hottest_days_overall.append(hottest_day_year)\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "hottest_days_cincinnati_df = pd.DataFrame(hottest_days_cincinnati).sort_values(by=\"YEAR\")\n",
    "hottest_days_florida_df = pd.DataFrame(hottest_days_florida).sort_values(by=\"YEAR\")\n",
    "hottest_days_overall_df = pd.DataFrame(hottest_days_overall).sort_values(by=\"YEAR\")\n",
    "\n",
    "# Display results in formatted tables\n",
    "print(\"\\nHottest Days by Year (Cincinnati):\\n\")\n",
    "print(tabulate(hottest_days_cincinnati_df, headers=\"keys\", tablefmt=\"fancy_grid\", floatfmt=\".1f\", showindex=False))\n",
    "\n",
    "print(\"\\nHottest Days by Year (Florida):\\n\")\n",
    "print(tabulate(hottest_days_florida_df, headers=\"keys\", tablefmt=\"fancy_grid\", floatfmt=\".1f\", showindex=False))\n",
    "\n",
    "print(\"\\nOverall Hottest Day by Year (Cincinnati and Florida):\\n\")\n",
    "print(tabulate(hottest_days_overall_df, headers=\"keys\", tablefmt=\"fancy_grid\", floatfmt=\".1f\", showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92f12467-9ed8-437f-bcdc-975c78dc2180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 4\n",
      "\n",
      "Coldest Day Overall in March (2015-2024) across Cincinnati and Florida:\n",
      "\n",
      "╒════════╤══════════════╤══════════════════════════════════════════════════╤════════════╤═════════════════╕\n",
      "│   Year │   Station ID │ Station Name                                     │ Date       │   Min Temp (°F) │\n",
      "╞════════╪══════════════╪══════════════════════════════════════════════════╪════════════╪═════════════════╡\n",
      "│   2015 │  72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2015-03-06 │             3.2 │\n",
      "╘════════╧══════════════╧══════════════════════════════════════════════════╧════════════╧═════════════════╛\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Prevent scientific notation for large numbers in station IDs\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "print(\"\\nAnswer to Question 4:\")\n",
    "\n",
    "# Directory and years range\n",
    "data_directory = \"./weather_data\"\n",
    "years = range(2015, 2025)\n",
    "stations = [\"72429793812\", \"99495199999\"]\n",
    "\n",
    "# List to store coldest day data for each station across all years\n",
    "march_min_temps = []\n",
    "\n",
    "# Find the coldest day in March across all years for each station\n",
    "for year in years:\n",
    "    for station in stations:\n",
    "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "            march_df = df[df['DATE'].dt.month == 3]\n",
    "\n",
    "            # Filter out invalid temperature values\n",
    "            march_df = march_df[march_df[\"MIN\"] != 9999.9]\n",
    "            \n",
    "            # Find the coldest day in March for this file, if available\n",
    "            if not march_df.empty:\n",
    "                coldest_day = march_df.loc[march_df[\"MIN\"].idxmin()]\n",
    "                march_min_temps.append({\n",
    "                    \"YEAR\": year,\n",
    "                    \"STATION\": str(coldest_day[\"STATION\"]),  # Ensure Station ID is stored as a string\n",
    "                    \"NAME\": coldest_day[\"NAME\"],\n",
    "                    \"DATE\": coldest_day[\"DATE\"],\n",
    "                    \"MIN\": coldest_day[\"MIN\"]\n",
    "                })\n",
    "\n",
    "# Convert the list to a DataFrame and find the overall coldest day in March across all years\n",
    "all_march_min_df = pd.DataFrame(march_min_temps)\n",
    "coldest_overall_day = all_march_min_df.loc[all_march_min_df[\"MIN\"].idxmin()]\n",
    "\n",
    "# Prepare data for display\n",
    "results = [\n",
    "    {\n",
    "        \"Year\": int(coldest_overall_day[\"YEAR\"]),\n",
    "        \"Station ID\": coldest_overall_day[\"STATION\"],\n",
    "        \"Station Name\": coldest_overall_day[\"NAME\"],\n",
    "        \"Date\": coldest_overall_day[\"DATE\"].strftime(\"%Y-%m-%d\"),\n",
    "        \"Min Temp (°F)\": round(coldest_overall_day[\"MIN\"], 1)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display the result in a well-formatted table\n",
    "print(\"\\nColdest Day Overall in March (2015-2024) across Cincinnati and Florida:\\n\")\n",
    "print(tabulate(results, headers=\"keys\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b50aa62-3709-446b-8fed-3add3229145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 5\n",
      "\n",
      "Year with Most Precipitation for Cincinnati and Florida:\n",
      "\n",
      "╒════════╤═════════════╤══════════════════════════════════════════════════╤═════════════╕\n",
      "│   Year │     Station │ Station Name                                     │   Mean PRCP │\n",
      "╞════════╪═════════════╪══════════════════════════════════════════════════╪═════════════╡\n",
      "│   2024 │ 72429793812 │ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │        5.44 │\n",
      "├────────┼─────────────┼──────────────────────────────────────────────────┼─────────────┤\n",
      "│   2015 │ 99495199999 │ SEBASTIAN INLET STATE PARK, FL US                │        0    │\n",
      "╘════════╧═════════════╧══════════════════════════════════════════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Prevent scientific notation for large numbers in station IDs\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "print(\"\\nAnswer to Question 5:\")\n",
    "\n",
    "# Directory and years range\n",
    "data_directory = \"./weather_data\"\n",
    "years = range(2015, 2025)\n",
    "\n",
    "# Calculate mean precipitation by year for Cincinnati\n",
    "cincinnati_precip_data = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = f\"{data_directory}/{year}_72429793812.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Filter out invalid precipitation values\n",
    "        df = df[df[\"PRCP\"] != 9999.9]\n",
    "        if not df.empty:\n",
    "            mean_prcp = df[\"PRCP\"].mean()\n",
    "            cincinnati_precip_data.append({\n",
    "                \"YEAR\": year,\n",
    "                \"STATION\": str(df[\"STATION\"].iloc[0]),  # Convert to string to preserve full ID\n",
    "                \"NAME\": df[\"NAME\"].iloc[0],\n",
    "                \"Mean_PRCP\": mean_prcp\n",
    "            })\n",
    "\n",
    "cincinnati_precip_df = pd.DataFrame(cincinnati_precip_data)\n",
    "cincinnati_result = cincinnati_precip_df.loc[cincinnati_precip_df[\"Mean_PRCP\"].idxmax()]\n",
    "\n",
    "# Calculate mean precipitation by year for Florida (excluding 2016 as data is unavailable)\n",
    "florida_precip_data = []\n",
    "\n",
    "for year in years:\n",
    "    if year == 2016:\n",
    "        continue\n",
    "    file_path = f\"{data_directory}/{year}_99495199999.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df[\"PRCP\"] != 9999.9]\n",
    "        if not df.empty:\n",
    "            mean_prcp = df[\"PRCP\"].mean()\n",
    "            florida_precip_data.append({\n",
    "                \"YEAR\": year,\n",
    "                \"STATION\": str(df[\"STATION\"].iloc[0]),  # Convert to string to preserve full ID\n",
    "                \"NAME\": df[\"NAME\"].iloc[0],\n",
    "                \"Mean_PRCP\": mean_prcp\n",
    "            })\n",
    "\n",
    "florida_precip_df = pd.DataFrame(florida_precip_data)\n",
    "florida_result = florida_precip_df.loc[florida_precip_df[\"Mean_PRCP\"].idxmax()]\n",
    "\n",
    "# Prepare data for display\n",
    "results = [\n",
    "    {\n",
    "        \"Year\": int(cincinnati_result[\"YEAR\"]),\n",
    "        \"Station\": cincinnati_result[\"STATION\"],\n",
    "        \"Station Name\": cincinnati_result[\"NAME\"],\n",
    "        \"Mean PRCP\": round(cincinnati_result[\"Mean_PRCP\"], 2)\n",
    "    },\n",
    "    {\n",
    "        \"Year\": int(florida_result[\"YEAR\"]),\n",
    "        \"Station\": florida_result[\"STATION\"],\n",
    "        \"Station Name\": florida_result[\"NAME\"],\n",
    "        \"Mean PRCP\": round(florida_result[\"Mean_PRCP\"], 2)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display the results in a well-formatted table\n",
    "print(\"\\nYear with Most Precipitation for Cincinnati and Florida:\\n\")\n",
    "print(tabulate(results, headers=\"keys\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d66fa68-7f2d-45ba-8cd9-33d2b23018f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 6:\n",
      "\n",
      "Percentage of Missing Values for Wind Gust (column GUST) for Cincinnati and Florida in 2024:\n",
      "\n",
      "Cincinnati: 39.53%\n",
      "Florida: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nAnswer to Question 6:\")\n",
    "\n",
    "# Define file paths for 2024 data for Cincinnati and Florida\n",
    "cincinnati_2024_file = \"./weather_data/2024_72429793812.csv\"\n",
    "florida_2024_file = \"./weather_data/2024_99495199999.csv\"\n",
    "\n",
    "# Load 2024 data for Cincinnati and Florida if the files exist\n",
    "if os.path.exists(cincinnati_2024_file):\n",
    "    cincinnati_df = pd.read_csv(cincinnati_2024_file)\n",
    "    # Count missing GUST values (marked as 999.9) and calculate percentage\n",
    "    cincinnati_missing_count = (cincinnati_df[\"GUST\"] == 999.9).sum()\n",
    "    cincinnati_total_count = len(cincinnati_df)\n",
    "    cincinnati_missing_percentage = (cincinnati_missing_count / cincinnati_total_count) * 100\n",
    "else:\n",
    "    cincinnati_missing_percentage = None\n",
    "\n",
    "if os.path.exists(florida_2024_file):\n",
    "    florida_df = pd.read_csv(florida_2024_file)\n",
    "    florida_missing_count = (florida_df[\"GUST\"] == 999.9).sum()\n",
    "    florida_total_count = len(florida_df)\n",
    "    florida_missing_percentage = (florida_missing_count / florida_total_count) * 100\n",
    "else:\n",
    "    florida_missing_percentage = None\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nPercentage of Missing Values for Wind Gust (column GUST) for Cincinnati and Florida in 2024:\\n\")\n",
    "if cincinnati_missing_percentage is not None:\n",
    "    print(f\"Cincinnati: {cincinnati_missing_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"Cincinnati data file for 2024 not found.\")\n",
    "\n",
    "if florida_missing_percentage is not None:\n",
    "    print(f\"Florida: {florida_missing_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"Florida data file for 2024 not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cca06c2-1960-4603-92bb-36af6ad86f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 7:\n",
      "\n",
      "Temperature Statistics for Cincinnati for Each Month in 2020:\n",
      "\n",
      "╒═══════════╤═════════════╤══════════════════════════╤═══════════════╤═════════════╕\n",
      "│ MONTH     │   Mean_TEMP │   StandardDeviation_TEMP │   Median_TEMP │   Mode_TEMP │\n",
      "╞═══════════╪═════════════╪══════════════════════════╪═══════════════╪═════════════╡\n",
      "│ January   │       37.95 │                     8.35 │         37.70 │       24.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ February  │       36.59 │                     7.90 │         36.00 │       25.90 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ March     │       49.07 │                     8.78 │         47.80 │       39.60 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ April     │       51.78 │                     7.31 │         51.10 │       39.20 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ May       │       60.89 │                     9.31 │         63.70 │       73.90 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ June      │       72.55 │                     4.90 │         73.95 │       70.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ July      │       77.60 │                     2.34 │         77.90 │       72.50 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ August    │       73.35 │                     3.49 │         73.70 │       67.40 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ September │       66.10 │                     7.12 │         66.15 │       54.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ October   │       55.19 │                     6.73 │         54.00 │       41.40 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ November  │       48.00 │                     6.83 │         47.70 │       47.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ December  │       35.99 │                     6.64 │         35.20 │       32.10 │\n",
      "╘═══════════╧═════════════╧══════════════════════════╧═══════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"\\nAnswer to Question 7:\")\n",
    "\n",
    "# File path for Cincinnati 2020 data\n",
    "cincinnati_2020_file = \"./weather_data/2020_72429793812.csv\"\n",
    "\n",
    "# Load 2020 data for Cincinnati if the file exists\n",
    "if os.path.exists(cincinnati_2020_file):\n",
    "    df = pd.read_csv(cincinnati_2020_file)\n",
    "    \n",
    "    # Filter out invalid temperature values and rows with missing TEMP values\n",
    "    df = df[df[\"TEMP\"] != 9999.9].dropna(subset=[\"TEMP\"])\n",
    "    df[\"TEMP\"] = df[\"TEMP\"].astype(float)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df[\"MONTH\"] = df[\"DATE\"].dt.month_name()  # Get month name directly\n",
    "\n",
    "    # Define the month order\n",
    "    month_order = {\n",
    "        \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \"May\": 5, \"June\": 6,\n",
    "        \"July\": 7, \"August\": 8, \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "    }\n",
    "\n",
    "    # Calculate statistics for each month\n",
    "    stats_results = []\n",
    "    for month in df[\"MONTH\"].unique():\n",
    "        month_df = df[df[\"MONTH\"] == month]\n",
    "        if not month_df.empty:\n",
    "            mean_temp = month_df[\"TEMP\"].mean()\n",
    "            std_dev_temp = month_df[\"TEMP\"].std()\n",
    "            median_temp = month_df[\"TEMP\"].median()\n",
    "            \n",
    "            # Calculate mode, handling cases where mode might be a scalar\n",
    "            mode_result = stats.mode(month_df[\"TEMP\"], nan_policy='omit')\n",
    "            mode_temp = mode_result.mode[0] if hasattr(mode_result.mode, \"__len__\") else mode_result.mode\n",
    "            \n",
    "            stats_results.append({\n",
    "                \"MONTH\": month,\n",
    "                \"Mean_TEMP\": mean_temp,\n",
    "                \"StandardDeviation_TEMP\": std_dev_temp,\n",
    "                \"Median_TEMP\": median_temp,\n",
    "                \"Mode_TEMP\": mode_temp\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame and sort by month order\n",
    "    final_stats_df = pd.DataFrame(stats_results)\n",
    "    final_stats_df[\"MONTH_ORDER\"] = final_stats_df[\"MONTH\"].map(month_order)\n",
    "    final_stats_df = final_stats_df.sort_values(by=\"MONTH_ORDER\").drop(columns=\"MONTH_ORDER\")\n",
    "\n",
    "    # Display results in a well-formatted table\n",
    "    print(\"\\nTemperature Statistics for Cincinnati for Each Month in 2020:\\n\")\n",
    "    print(tabulate(final_stats_df, headers=\"keys\", tablefmt=\"fancy_grid\", floatfmt=\".2f\", showindex=False))\n",
    "else:\n",
    "    print(\"Cincinnati 2020 data file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "278d66d5-116f-43b6-9378-881307c322b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 8:\n",
      "\n",
      "Top 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\n",
      "\n",
      "╒══════════════════════════════════════════════════╤════════════╤════════╤════════╤══════════════╕\n",
      "│ NAME                                             │ DATE       │   TEMP │   WDSP │   Wind_Chill │\n",
      "╞══════════════════════════════════════════════════╪════════════╪════════╪════════╪══════════════╡\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-07 │  10.50 │   7.00 │        -0.41 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-31 │  11.00 │   5.30 │         2.03 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-27 │  13.00 │   5.80 │         3.82 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-28 │  13.60 │   5.80 │         4.53 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-06 │  13.60 │   5.50 │         4.87 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-08 │  15.90 │   5.20 │         7.93 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-25 │  25.80 │  13.50 │        14.29 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-30 │  21.60 │   5.30 │        14.54 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-05 │  22.20 │   5.80 │        14.75 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-26 │  23.30 │   6.20 │        15.69 │\n",
      "╘══════════════════════════════════════════════════╧════════════╧════════╧════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"\\nAnswer to Question 8:\")\n",
    "\n",
    "# File path for Cincinnati 2017 data\n",
    "cincinnati_2017_file = \"./weather_data/2017_72429793812.csv\"\n",
    "\n",
    "# Load the 2017 data for Cincinnati\n",
    "if os.path.exists(cincinnati_2017_file):\n",
    "    df = pd.read_csv(cincinnati_2017_file)\n",
    "    \n",
    "    # Convert TEMP and WDSP to float and filter for relevant conditions\n",
    "    df[\"TEMP\"] = pd.to_numeric(df[\"TEMP\"], errors=\"coerce\")\n",
    "    df[\"WDSP\"] = pd.to_numeric(df[\"WDSP\"], errors=\"coerce\")\n",
    "    filtered_df = df[(df[\"TEMP\"] < 50) & (df[\"WDSP\"] > 3)].dropna(subset=[\"TEMP\", \"WDSP\"])\n",
    "\n",
    "    # Calculate Wind Chill using the formula\n",
    "    filtered_df[\"Wind_Chill\"] = (\n",
    "        35.74 + (0.6215 * filtered_df[\"TEMP\"]) - (35.75 * (filtered_df[\"WDSP\"] ** 0.16)) +\n",
    "        (0.4275 * filtered_df[\"TEMP\"] * (filtered_df[\"WDSP\"] ** 0.16))\n",
    "    )\n",
    "\n",
    "    # Get the top 10 days with the lowest Wind Chill\n",
    "    top_10_lowest_wc = filtered_df.nsmallest(10, \"Wind_Chill\")[[\"NAME\", \"DATE\", \"TEMP\", \"WDSP\", \"Wind_Chill\"]]\n",
    "\n",
    "    # Display results in a well-formatted table\n",
    "    print(\"\\nTop 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\\n\")\n",
    "    print(tabulate(top_10_lowest_wc, headers=\"keys\", tablefmt=\"fancy_grid\", floatfmt=\".2f\", showindex=False))\n",
    "else:\n",
    "    print(\"Cincinnati 2017 data file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9bdbdb9-46ed-4f45-a01c-448f59786193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 9:\n",
      "\n",
      "Number of Days with Extreme Weather Conditions in Florida from 2015 to 2024: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nAnswer to Question 9:\")\n",
    "\n",
    "# Directory and years for Florida files\n",
    "data_directory = \"./weather_data\"\n",
    "years = [y for y in range(2015, 2025) if y != 2016]  # Exclude 2016 if data is unavailable\n",
    "\n",
    "# Initialize a counter for extreme weather days\n",
    "extreme_weather_days_count = 0\n",
    "\n",
    "# Load and process data for each year in the specified range\n",
    "for year in years:\n",
    "    florida_file = f\"{data_directory}/{year}_99495199999.csv\"\n",
    "    \n",
    "    if os.path.exists(florida_file):\n",
    "        df = pd.read_csv(florida_file)\n",
    "        \n",
    "        # Ensure each FRSHTT value is a six-character string\n",
    "        df['FRSHTT'] = df['FRSHTT'].astype(str).str.zfill(6)\n",
    "        \n",
    "        # Count days with any extreme weather indicator\n",
    "        extreme_weather_days = df[df['FRSHTT'].apply(\n",
    "            lambda x: any(x[i] == \"1\" for i in range(6))\n",
    "        )]\n",
    "        \n",
    "        # Update the total count of extreme weather days\n",
    "        extreme_weather_days_count += len(extreme_weather_days)\n",
    "\n",
    "# Display the result\n",
    "print(f\"\\nNumber of Days with Extreme Weather Conditions in Florida from 2015 to 2024: {extreme_weather_days_count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f09c1f8b-bf35-4c09-9be1-0b7dbb172b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer to Question 10:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m data_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./weather_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m cincinnati_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_72429793812.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m2023\u001b[39m]]\n\u001b[1;32m---> 11\u001b[0m cincinnati_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_csv(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m cincinnati_files \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file)])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Filter data for November and December, remove invalid temperatures, and convert dates\u001b[39;00m\n\u001b[0;32m     14\u001b[0m cincinnati_data \u001b[38;5;241m=\u001b[39m cincinnati_data[cincinnati_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAX\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m9999.9\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nAnswer to Question 10:\")\n",
    "\n",
    "# Load 2022 and 2023 data for Cincinnati\n",
    "data_directory = \"./weather_data\"\n",
    "cincinnati_files = [f\"{data_directory}/{year}_72429793812.csv\" for year in [2022, 2023]]\n",
    "cincinnati_data = pd.concat([pd.read_csv(file) for file in cincinnati_files if os.path.exists(file)])\n",
    "\n",
    "# Filter data for November and December, remove invalid temperatures, and convert dates\n",
    "cincinnati_data = cincinnati_data[cincinnati_data[\"MAX\"] != 9999.9]\n",
    "cincinnati_data[\"DATE\"] = pd.to_datetime(cincinnati_data[\"DATE\"])\n",
    "cincinnati_data[\"YEAR\"] = cincinnati_data[\"DATE\"].dt.year\n",
    "cincinnati_data[\"MONTH\"] = cincinnati_data[\"DATE\"].dt.month\n",
    "\n",
    "# Extract max temperatures for November and December for each year\n",
    "november_data = cincinnati_data[cincinnati_data[\"MONTH\"] == 11].groupby(\"YEAR\")[\"MAX\"].max().reset_index()\n",
    "december_data = cincinnati_data[cincinnati_data[\"MONTH\"] == 12].groupby(\"YEAR\")[\"MAX\"].max().reset_index()\n",
    "\n",
    "# Prepare data for modeling\n",
    "november_years = november_data[\"YEAR\"].values.reshape(-1, 1)\n",
    "november_temps = november_data[\"MAX\"].values\n",
    "december_years = december_data[\"YEAR\"].values.reshape(-1, 1)\n",
    "december_temps = december_data[\"MAX\"].values\n",
    "\n",
    "# Train linear regression models for November and December\n",
    "nov_model = LinearRegression().fit(november_years, november_temps)\n",
    "dec_model = LinearRegression().fit(december_years, december_temps)\n",
    "\n",
    "# Predict max temperatures for November and December 2024\n",
    "nov_pred_2024 = nov_model.predict(np.array([[2024]]))[0]\n",
    "dec_pred_2024 = dec_model.predict(np.array([[2024]]))[0]\n",
    "\n",
    "# Display predictions\n",
    "print(\"Predicted Maximum Temperatures for Cincinnati:\")\n",
    "print(f\"November 2024: {nov_pred_2024:.2f}°F\")\n",
    "print(f\"December 2024: {dec_pred_2024:.2f}°F\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e289b-0803-4c19-9b0a-4935c06c883e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
